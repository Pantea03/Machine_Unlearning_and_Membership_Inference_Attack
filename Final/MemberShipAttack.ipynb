{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtmIknT_9nMp"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class CIFAR10Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CIFAR10Classifier, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
        "    self.dropout1 = nn.Dropout2d(0.25)\n",
        "    self.dropout2 = nn.Dropout2d(0.5)\n",
        "    self.fc1 = nn.Linear(6272, 64)\n",
        "    self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.dropout1(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout2(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "\n",
        "\n",
        "\n",
        "def load_fashion_mnist_dataset():\n",
        "    from keras.datasets import fashion_mnist\n",
        "\n",
        "    # load dataset\n",
        "    (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "    # summarize loaded dataset\n",
        "    print('Train: X=%s, y=%s' % (trainX.shape, trainY.shape))\n",
        "    print('Test: X=%s, y=%s' % (testX.shape, testY.shape))\n",
        "\n",
        "    # reshape dataset to have a single channel\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\n",
        "    # one hot encode target values\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "\n",
        "    return (trainX, trainY), (testX, testY)\n",
        "\n",
        "# Set hyper-parameters for our training of neural networks\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCH = 5\n",
        "VERBOSE = 1\n",
        "\n",
        "TRAINING_SIZE = 3000\n",
        "TEST_SIZE = 2000\n",
        "\n",
        "# No of target models\n",
        "NUM_TARGET = 1\n",
        "# No of shadow models\n",
        "NUM_SHADOW = 2\n",
        "\n",
        "# Label value \"in\" for records present in training data of shadow models\n",
        "IN = 1\n",
        "# Label value \"out\" for records not present in training data of shadow models\n",
        "OUT = 0\n",
        "\n",
        "def sample_data(train_data, test_data, num_sets):\n",
        "    (x_train, y_train), (x_test, y_test) = train_data, test_data\n",
        "    new_x_train, new_y_train = [], []\n",
        "    new_x_test, new_y_test = [], []\n",
        "    for i in range(num_sets):\n",
        "        x_temp, y_temp = resample(x_train, y_train, n_samples=TRAINING_SIZE, random_state=0)\n",
        "        new_x_train.append(x_temp)\n",
        "        new_y_train.append(y_temp)\n",
        "        x_temp, y_temp = resample(x_test, y_test, n_samples=TEST_SIZE, random_state=0)\n",
        "        new_x_test.append(x_temp)\n",
        "        new_y_test.append(y_temp)\n",
        "    return (new_x_train, new_y_train), (new_x_test, new_y_test)\n",
        "\n",
        "def get_attack_dataset(models, train_data, test_data, num_models, data_size):\n",
        "    # generate dataset for the attack model\n",
        "    (x_train, y_train), (x_test, y_test) = train_data, test_data\n",
        "    # set number of classes for the attack model\n",
        "    num_classes = 10\n",
        "    x_data, y_data = [[] for _ in range(num_classes)], [[] for _ in range(num_classes)]\n",
        "    for i in range(num_models):\n",
        "        # IN data\n",
        "        x_temp, y_temp = resample(x_train[i], y_train[i], n_samples=data_size, random_state=0)\n",
        "        for j in range(data_size):\n",
        "            y_idx = np.argmax(y_temp[j])\n",
        "            x_data[y_idx].append(models[i].predict(x_temp[j:j+1], verbose=0)[0])\n",
        "            y_data[y_idx].append(IN)\n",
        "\n",
        "        # OUT data\n",
        "        x_temp, y_temp = resample(x_test[i], y_test[i], n_samples=data_size, random_state=0)\n",
        "        for j in range(data_size):\n",
        "            y_idx = np.argmax(y_temp[j])\n",
        "            x_data[y_idx].append(models[i].predict(x_temp[j:j+1], verbose=0)[0])\n",
        "            y_data[y_idx].append(OUT)\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "def build_fcnn_model_fashion_mnist():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def get_trained_keras_models(keras_model, train_data, test_data, num_models):\n",
        "    (x_train, y_train), (x_test, y_test) = train_data, test_data\n",
        "    models = []\n",
        "    for i in range(num_models):\n",
        "        models.append(tf.keras.models.clone_model(keras_model))\n",
        "        rms = tf.keras.optimizers.RMSprop(learning_rate=LEARNING_RATE, decay=1e-7)\n",
        "        models[i].compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])\n",
        "        models[i].fit(x_train[i], y_train[i], batch_size=32, epochs=EPOCH, verbose=VERBOSE, shuffle=True)\n",
        "        score = models[i].evaluate(x_test[i], y_test[i], verbose=VERBOSE)\n",
        "       # print('\\n', 'Model ', i, ' test accuracy:', score[1])\n",
        "    return models\n",
        "\n",
        "def get_trained_svm_models(train_data, test_data, num_models=1):\n",
        "    from sklearn import svm\n",
        "    (x_train, y_train), (x_test, y_test) = train_data, test_data\n",
        "    models = []\n",
        "    for i in range(num_models):\n",
        "        #print('Training svm model : ', i)\n",
        "        models.append(svm.SVC(gamma='scale', kernel='linear', verbose=VERBOSE))\n",
        "        models[i].fit(x_train[i], y_train[i])\n",
        "        score = models[i].score(x_test[i], y_test[i])\n",
        "        #print('SVM model ', i, 'score : ', score)\n",
        "    return models\n",
        "\n",
        "def membership_attack():\n",
        "    # load the pre-shuffled train and test data\n",
        "    (x_train, y_train), (x_test, y_test) = load_fashion_mnist_dataset()\n",
        "\n",
        "    # split the data for each model\n",
        "    target_train = (x_train[:TRAINING_SIZE*NUM_TARGET], y_train[:TRAINING_SIZE*NUM_TARGET])\n",
        "    target_test = (x_test[:TEST_SIZE*NUM_TARGET], y_test[:TEST_SIZE*NUM_TARGET])\n",
        "    target_train_data, target_test_data = sample_data(target_train, target_test, NUM_TARGET)\n",
        "\n",
        "    shadow_train = (x_train[TRAINING_SIZE*NUM_TARGET:], y_train[TRAINING_SIZE*NUM_TARGET:])\n",
        "    shadow_test = (x_test[TEST_SIZE*NUM_TARGET:], y_test[TEST_SIZE*NUM_TARGET:])\n",
        "    shadow_train_data, shadow_test_data = sample_data(shadow_train, shadow_test, NUM_SHADOW)\n",
        "\n",
        "    cnn_model = build_fcnn_model_fashion_mnist()\n",
        "\n",
        "    # compile the target model\n",
        "    target_models = get_trained_keras_models(cnn_model, target_train_data, target_test_data, NUM_TARGET)\n",
        "    # compile the shadow models\n",
        "    shadow_models = get_trained_keras_models(cnn_model, shadow_train_data, shadow_test_data, NUM_SHADOW)\n",
        "\n",
        "    # get train data for the attack model\n",
        "    attack_train = get_attack_dataset(shadow_models, shadow_train_data, shadow_test_data, NUM_SHADOW, TEST_SIZE)\n",
        "    # get test data for the attack model\n",
        "    attack_test = get_attack_dataset(target_models, target_train_data, target_test_data, NUM_TARGET, TEST_SIZE)\n",
        "\n",
        "    # training the attack model\n",
        "    #attack_model = get_trained_svm_models(attack_train, attack_test)\n",
        "    return attack_train, attack_test\n",
        "NUM_SHADOW = 2\n",
        "attack_train1, attack_test1 = membership_attack()\n"
      ],
      "metadata": {
        "id": "PoiJPnwVKkyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Subset, DataLoader, TensorDataset\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score ,f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = CIFAR10Classifier()\n",
        "state_dict = torch.load(\"model_state_dict.pth\", map_location=device)\n",
        "new_state_dict = {key.replace('_module.', ''): value for key, value in state_dict.items()}\n",
        "model.load_state_dict(new_state_dict)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "DATA_ROOT = '../cifar10'\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Load the indices from list.txt\n",
        "indices_file = 'list.txt' ############\n",
        "with open(indices_file, 'r') as f:\n",
        "    indices = [int(line.strip()) for line in f]\n",
        "\n",
        "full_train_dataset = CIFAR10(root=DATA_ROOT, train=True, download=True, transform=transform)\n",
        "test_dataset = CIFAR10(root=DATA_ROOT, train=False, download=True, transform=transform)\n",
        "\n",
        "train_indices_set = set(indices)\n",
        "all_indices = set(range(len(full_train_dataset)))\n",
        "other_indices = list(all_indices - train_indices_set)\n",
        "\n",
        "train_dataset = Subset(full_train_dataset, indices[:len(indices)//2])  ###########\n",
        "other_dataset = Subset(full_train_dataset, other_indices)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "other_loader = DataLoader(other_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Create labels\n",
        "train_labels = torch.ones(len(train_dataset)).to(device)\n",
        "other_labels = torch.zeros(len(other_dataset)).to(device)\n",
        "test_labels = torch.zeros(len(test_dataset)).to(device)\n",
        "####################################\n",
        "#if you have an attacker model for each class, modify the above code.\n",
        "####################################\n",
        "\n",
        "def extract_features(model, dataloader):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            inputs, _ = data\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            features.append(outputs)\n",
        "    return torch.cat(features).to(device)\n",
        "\n",
        "train_features = extract_features(model, train_loader)\n",
        "other_features = extract_features(model, other_loader)\n",
        "test_features = extract_features(model, test_loader)\n",
        "\n",
        "\n",
        "combined_features = torch.cat((train_features, other_features, test_features))\n",
        "combined_labels = torch.cat((train_labels, other_labels, test_labels))\n",
        "\n",
        "\n",
        "new_dataset = TensorDataset(combined_features, combined_labels)\n",
        "new_loader = DataLoader(new_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "#load your attacker model\n",
        "\n",
        "#############################################\n",
        "\n",
        "# Calculate training accuracy, confusion matrix, precision, and recall\n",
        "binary_classifier.eval()\n",
        "all_labels = []\n",
        "all_predicted = []\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in new_loader:\n",
        "        features, labels = features.to(device), labels.to(device)\n",
        "        outputs = get_trained_svm_models(features, attack_test).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_predicted.extend(predicted.cpu().numpy())\n",
        "\n",
        "accuracy = correct / total\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_predicted)\n",
        "precision = precision_score(all_labels, all_predicted)\n",
        "recall = recall_score(all_labels, all_predicted)\n",
        "f1 = f1_score(all_labels, all_predicted)\n",
        "\n",
        "print(f'Confusion Matrix:\\n{cm}')\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f'Training Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "K1yMQf2f2YqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b66758-d987-4b79-ea7c-a3948b6fcd00"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 9452  8766]\n",
            " [ 8361 13421]]\n",
            "Precision: 0.6049\n",
            "Recall: 0.6162\n",
            "F1 Score: 0.6105\n",
            "Training Accuracy: 0.5718\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "740px",
        "left": "0px",
        "right": "1628px",
        "top": "161px",
        "width": "253px"
      },
      "toc_section_display": "block",
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}