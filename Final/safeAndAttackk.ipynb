{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "\n",
        "\n",
        "def load_fashion_mnist_dataset():\n",
        "    from keras.datasets import fashion_mnist\n",
        "\n",
        "    # load dataset\n",
        "    (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "    # summarize loaded dataset\n",
        "    print('Train: X=%s, y=%s' % (trainX.shape, trainY.shape))\n",
        "    print('Test: X=%s, y=%s' % (testX.shape, testY.shape))\n",
        "\n",
        "    # reshape dataset to have a single channel\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\n",
        "    # one hot encode target values\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "\n",
        "    return (trainX, trainY), (testX, testY)\n",
        "\n",
        "# Set hyper-parameters for our training of neural networks\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCH = 5\n",
        "VERBOSE = 1\n",
        "\n",
        "TRAINING_SIZE = 3000\n",
        "TEST_SIZE = 2000\n",
        "\n",
        "# No of target models\n",
        "NUM_TARGET = 1\n",
        "# No of shadow models\n",
        "NUM_SHADOW = 2\n",
        "\n",
        "# Label value \"in\" for records present in training data of shadow models\n",
        "IN = 1\n",
        "# Label value \"out\" for records not present in training data of shadow models\n",
        "OUT = 0\n",
        "\n",
        "def sample_data(train_data, test_data, num_sets):\n",
        "    (x_train, y_train), (x_test, y_test) = train_data, test_data\n",
        "    new_x_train, new_y_train = [], []\n",
        "    new_x_test, new_y_test = [], []\n",
        "    for i in range(num_sets):\n",
        "        x_temp, y_temp = resample(x_train, y_train, n_samples=TRAINING_SIZE, random_state=0)\n",
        "        new_x_train.append(x_temp)\n",
        "        new_y_train.append(y_temp)\n",
        "        x_temp, y_temp = resample(x_test, y_test, n_samples=TEST_SIZE, random_state=0)\n",
        "        new_x_test.append(x_temp)\n",
        "        new_y_test.append(y_temp)\n",
        "    return (new_x_train, new_y_train), (new_x_test, new_y_test)\n",
        "\n",
        "def get_attack_dataset(models, train_data, test_data, num_models, data_size):\n",
        "    # generate dataset for the attack model\n",
        "    (x_train, y_train), (x_test, y_test) = train_data, test_data\n",
        "    # set number of classes for the attack model\n",
        "    num_classes = 10\n",
        "    x_data, y_data = [[] for _ in range(num_classes)], [[] for _ in range(num_classes)]\n",
        "    for i in range(num_models):\n",
        "        # IN data\n",
        "        x_temp, y_temp = resample(x_train[i], y_train[i], n_samples=data_size, random_state=0)\n",
        "        for j in range(data_size):\n",
        "            y_idx = np.argmax(y_temp[j])\n",
        "            x_data[y_idx].append(models[i].predict(x_temp[j:j+1], verbose=0)[0])\n",
        "            y_data[y_idx].append(IN)\n",
        "\n",
        "        # OUT data\n",
        "        x_temp, y_temp = resample(x_test[i], y_test[i], n_samples=data_size, random_state=0)\n",
        "        for j in range(data_size):\n",
        "            y_idx = np.argmax(y_temp[j])\n",
        "            x_data[y_idx].append(models[i].predict(x_temp[j:j+1], verbose=0)[0])\n",
        "            y_data[y_idx].append(OUT)\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "def build_fcnn_model_fashion_mnist():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),  # Add dropout with 50% rate\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def get_trained_keras_models(keras_model, train_data, test_data, num_models):\n",
        "    (x_train, y_train), (x_test, y_test) = train_data, test_data\n",
        "    models = []\n",
        "    for i in range(num_models):\n",
        "        models.append(tf.keras.models.clone_model(keras_model))\n",
        "        rms = tf.keras.optimizers.RMSprop(learning_rate=LEARNING_RATE)\n",
        "        models[i].compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])\n",
        "        models[i].fit(x_train[i], y_train[i], batch_size=32, epochs=EPOCH, verbose=VERBOSE, shuffle=True)\n",
        "        score = models[i].evaluate(x_test[i], y_test[i], verbose=VERBOSE)\n",
        "        print('\\n', 'Model ', i, ' test accuracy:', score[1])\n",
        "    return models\n",
        "\n",
        "def get_trained_svm_models(train_data, test_data, num_models=1):\n",
        "    from sklearn import svm\n",
        "    (x_train, y_train), (x_test, y_test) = train_data, test_data\n",
        "    models = []\n",
        "    for i in range(num_models):\n",
        "        print('Training svm model : ', i)\n",
        "        models.append(svm.SVC(gamma='scale', kernel='linear', verbose=VERBOSE))\n",
        "        models[i].fit(x_train[i], y_train[i])\n",
        "        score = models[i].score(x_test[i], y_test[i])\n",
        "        print('SVM model ', i, 'score : ', score)\n",
        "    return models\n",
        "\n",
        "def membership_attack():\n",
        "    # load the pre-shuffled train and test data\n",
        "    (x_train, y_train), (x_test, y_test) = load_fashion_mnist_dataset()\n",
        "\n",
        "    # split the data for each model\n",
        "    target_train = (x_train[:TRAINING_SIZE*NUM_TARGET], y_train[:TRAINING_SIZE*NUM_TARGET])\n",
        "    target_test = (x_test[:TEST_SIZE*NUM_TARGET], y_test[:TEST_SIZE*NUM_TARGET])\n",
        "    target_train_data, target_test_data = sample_data(target_train, target_test, NUM_TARGET)\n",
        "\n",
        "    shadow_train = (x_train[TRAINING_SIZE*NUM_TARGET:], y_train[TRAINING_SIZE*NUM_TARGET:])\n",
        "    shadow_test = (x_test[TEST_SIZE*NUM_TARGET:], y_test[TEST_SIZE*NUM_TARGET:])\n",
        "    shadow_train_data, shadow_test_data = sample_data(shadow_train, shadow_test, NUM_SHADOW)\n",
        "\n",
        "    cnn_model = build_fcnn_model_fashion_mnist()\n",
        "\n",
        "    # compile the target model\n",
        "    target_models = get_trained_keras_models(cnn_model, target_train_data, target_test_data, NUM_TARGET)\n",
        "    # compile the shadow models\n",
        "    shadow_models = get_trained_keras_models(cnn_model, shadow_train_data, shadow_test_data, NUM_SHADOW)\n",
        "\n",
        "    # get train data for the attack model\n",
        "    attack_train = get_attack_dataset(shadow_models, shadow_train_data, shadow_test_data, NUM_SHADOW, TEST_SIZE)\n",
        "    # get test data for the attack model\n",
        "    attack_test = get_attack_dataset(target_models, target_train_data, target_test_data, NUM_TARGET, TEST_SIZE)\n",
        "\n",
        "    # training the attack model\n",
        "    attack_model = get_trained_svm_models(attack_train, attack_test)\n",
        "\n",
        "NUM_SHADOW = 2\n",
        "membership_attack()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KORi4b9lsfCm",
        "outputId": "e8da451e-40d9-4faa-e97d-43646f4d4165"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28), y=(10000,)\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "94/94 [==============================] - 1s 4ms/step - loss: 24.4152 - accuracy: 0.3330\n",
            "Epoch 2/5\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 2.3659 - accuracy: 0.4293\n",
            "Epoch 3/5\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 1.9294 - accuracy: 0.4753\n",
            "Epoch 4/5\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 1.7721 - accuracy: 0.5003\n",
            "Epoch 5/5\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 1.7717 - accuracy: 0.4990\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.8605 - accuracy: 0.5755\n",
            "\n",
            " Model  0  test accuracy: 0.5755000114440918\n",
            "Epoch 1/5\n",
            "94/94 [==============================] - 1s 3ms/step - loss: 28.6290 - accuracy: 0.3900\n",
            "Epoch 2/5\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 2.2916 - accuracy: 0.3817\n",
            "Epoch 3/5\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 1.9308 - accuracy: 0.4120\n",
            "Epoch 4/5\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 1.7087 - accuracy: 0.4530\n",
            "Epoch 5/5\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 1.6937 - accuracy: 0.4740\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.3593 - accuracy: 0.6210\n",
            "\n",
            " Model  0  test accuracy: 0.6209999918937683\n",
            "Epoch 1/5\n",
            "94/94 [==============================] - 1s 3ms/step - loss: 24.4149 - accuracy: 0.3767\n",
            "Epoch 2/5\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 2.3103 - accuracy: 0.3637\n",
            "Epoch 3/5\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 1.9929 - accuracy: 0.4233\n",
            "Epoch 4/5\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 1.8375 - accuracy: 0.4540\n",
            "Epoch 5/5\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 1.7843 - accuracy: 0.4907\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.3897 - accuracy: 0.5945\n",
            "\n",
            " Model  1  test accuracy: 0.5945000052452087\n",
            "Training svm model :  0\n",
            "[LibSVM]SVM model  0 score :  0.48118279569892475\n"
          ]
        }
      ]
    }
  ]
}